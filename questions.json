[
    {
        "question": "Which enterprise Security framework provides a mechanism for running preconfigured actions within the Splunk platform or integrating with external applications?",
        "answers": [
          { "text": "Asset and Identity", "correct": false },
          { "text": "Notable Events", "correct": false },
          { "text": "Threat Intelligence", "correct": false },
          { "text": "Adaptive Response", "correct": true }
        ],
        "explanation": "ANSWER: D. Adaptive Response \n The Adaptive Response framework allows for the execution of preconfigured actions, either within Splunk or by integrating with external applications and tools. It enables security teams to automate and streamline their responses to security incidents, such as quarantaining hosts, disabling accounts or notifying relevant personnel"
    },
    {
        "question": "Which of the following Splunk enterprise features allows industry frameworks such as CIS Critical Security Controls, MITTRE ATT&CK and the Lockhead Martin Cyber Kill Chain top be mapped to correlation search results?",
        "answers": [
          { "text": "Annotations", "correct": true },
          { "text": "Playbooks", "correct": false },
          { "text": "Comments", "correct": false },
          { "text": "Enrichments", "correct": false }
        ],
        "explanation": "ANSWER: A. Annotations \n Annotations allow users to map correlation serach results to established industry frameworks. This mapping enables organizations to align their security monitoring and detection with recognized best practices and methodologies, providing valuable contect for security events and supporting standardized reporting and analysis."
    },
    {
        "question": "Which of the following is the primary benefit of using the CIM in Splunk?",
        "answers": [
          { "text": "It allows for easier correlation of data from different sources", "correct": true },
          { "text": "It improves the performance of search queries on raw data.", "correct": false },
          { "text": "It enables the use of advanced machine learning algorithms.", "correct": false },
          { "text": "It automatically detects and blocks cyber threats.", "correct": false }
        ],
        "explanation": "ANSWER: A. It allows for easier correlation of data from different sources \n The Commaon Information Model (CIM) in Splunk provides a standardized model that normaliuzed data from various sources into a consistent structure.  This eneables easier correlation of data from different sources, as fields and event types are mapped to common formats. The CIM is essential for improving the usability and effectiveness of security and operational use cases in Splunk"
    },
    {
        "question": "Tactics, Techniques, and Procedures (TTPs) are methods or behaviors utilized by attackers. In which framework are these categorized?",
        "answers": [
          { "text": "NIST 800-53", "correct": false },
          { "text": "ISO 27000", "correct": false },
          { "text": "CIS18", "correct": false },
          { "text": "MITRE ATT&CK", "correct": true }
        ],
        "explanation": "ANSWER: D. MITRE ATT&CK \n The MITRE ATT&CK framework categorizes Tactics, Techniques, and Procedures (TTPs) used by attackers. This framework provides a comprehensive matrix of attacker behaviors, detailing how adversaries accomplish various goals (Tactics), the specific methods they use (Techniques), and how these actions are executed (Procedures). It is widely used for threat intelligence, detection, and response in cybersecurity."
    },
    {
        "question": "A threat hunter executed a hunt based on the following hypothesis: As an actor, I want to plant rundll32 for proxy execution of malicious code and leverage Cobalt Strike for Command and Control. Relevant logs and artifacts such as Sysmon, netflow, IDS alerts, and EDR logs were searched, and the hunter is confident in the conclusion that Cobalt Strike is not present in the company’s environment. Which of the following best describes the outcome of this threat hunt?",
        "answers": [
          { "text": "The threat hunt was successful because the hypothesis was not proven.", "correct": false },
          { "text": "The threat hunt failed because the hypothesis was not proven.", "correct": false },
          { "text": "The threat hunt failed because no malicious activity was identified.", "correct": false },
          { "text": "The threat hunt was successful in providing strong evidence that the tactic and tool is not present in the environmen", "correct": true }
        ],
        "explanation": "ANSWER: D. The threat hunt was successful in providing strong evidence that the tactic and tool is not present in the environmen \n  A threat hunt is considered successful when it provides actionable insights or strong evidence about the presence or absence of malicious activity or tools. In this case, the hunter's investigation into the hypothesis that Cobalt Strike and rundll32 were used for malicious activity resulted in conclusive evidence that these were not present in the environment. This outcome supports a secure posture and validates the effectiveness of detection capabilities, which is a successful result for the hunt."
    },
    {
        "question": "An analyst notices that one of their servers is sending an unusually large amount of traffic, gigabytes more than normal, to a single system on the Internet. There doesn’t seem to be any associated increase in incoming traffic. What type of threat actor activity might this represent?",
        "answers": [
          { "text": "Data exfiltration", "correct": true },
          { "text": "Network reconnaissance", "correct": false },
          { "text": "Data infiltration", "correct": false },
          { "text": "Lateral movement", "correct": false }
        ],
        "explanation": "ANSWER: A. Data exfiltration \n  The behavior described—where a server is sending an unusually large amount of outgoing traffic to a single external system without a corresponding increase in incoming traffic—is characteristic of data exfiltration. This occurs when an attacker extracts sensitive data or files from a network to an external destination. The lack of incoming traffic suggests that the activity is focused on sending data out, rather than typical bi-directional communication, reconnaissance, or lateral movement."
    },
    {
        "question": "In which phase of the Continuous Monitoring cycle are suggestions and improvements typically made?",
        "answers": [
          { "text": "Define and Predict", "correct": false },
          { "text": "Establish and Architect", "correct": false },
          { "text": "Analyze and Report", "correct": true },
          { "text": "Implement and Collect", "correct": false }
        ],
        "explanation": "ANSWER: C. Analyze and Report \n In the Analyze and Report phase of the Continuous Monitoring cycle, data collected from monitoring activities is analyzed to identify security issues, trends, and gaps. During this phase, insights from the analysis are used to generate reports, which often include suggestions and improvements for mitigating risks, addressing vulnerabilities, and enhancing the overall security posture. This feedback loop is critical for ensuring the continuous improvement of monitoring processes and security strategies."
    },
    {
        "question": "An analyst is not sure that all of the potential data sources at her company are being correctly or completely utilized by Splunk and Enterprise Security. Which of the following might she suggest using, in order to perform an analysis of the data types available and some of their potential security uses?",
        "answers": [
          { "text": "Splunk ITSI", "correct": false },
          { "text": "Splunk Security Essentials", "correct": true },
          { "text": "Splunk SOAR", "correct": false },
          { "text": "Splunk Intelligence Management", "correct": false }
        ],
        "explanation": "ANSWER: B. Splunk Security Essentials \n Splunk Security Essentials is a free application that helps analysts and security teams explore the data sources available in their environment and understand their potential security use cases. It provides guidance on how to make better use of data, mapping it to specific security frameworks and best practices. Analysts can use it to analyze data types and their potential for security monitoring, correlation and detection within Splunk Enterprise Security."
    },
    {
        "question": "During their shift, an analyst receives an alert about an executable being run from C:\\Windows\\Temp. Why should this be investigated further?",
        "answers": [
          { "text": "Temp directories aren’t owned by any particular user, making it difficult to track the process owner when files are executed.", "correct": false },
          { "text": "Temp directories are flagged as non-executable, meaning that no files stored within can be executed, and this executable was run from that directory", "correct": false },
          { "text": "Temp directories contain the system page file and the virtual memory file, meaning the attacker can use their malware to read the in memory values of running programs", "correct": false },
          { "text": "Temp directories are world writable thus allowing attackers a place to drop, stage, and execute malware on a system without needing to worry about file permissions", "correct": true }
        ],
        "explanation": "ANSWER: D \n The C:\\Windows\\Temp directory is commonly used as a staging area by attackers because it is world writable, meaning any user can write files to it. This makes it an ideal location for dropping, staging, and executing malicious files without needing elevated permissions. Executables running from such directories are suspicious and warrant investigation, as legitimate processes typically do not execute from these locations. This behavior often indicates potential malware activity or unauthorized actions."
    },
    {
        "question": "An analyst would like to visualize threat objects across their environment and chronological risk events for a Risk Object in Incident Review. Where would they find this?",
        "answers": [
          { "text": "Running the Risk Analysis Adaptive Response action within the Notable Event.", "correct": false },
          { "text": "Via a workflow action for the Risk Investigation dashboard.", "correct": false },
          { "text": "Via the Risk Analysis dashboard under the Security Intelligence tab in Enterprise Security.", "correct": false },
          { "text": "Clicking the risk event count to open the Risk Event Timeline", "correct": true }
        ],
        "explanation": "ANSWER: D \n In Splunk Enterprise Security, an analyst can visualize threat objects and the chronological risk events associated with a Risk Object by clicking the risk event count within Incident Review. This action opens the Risk Event Timeline, providing a detailed, time-ordered view of risk events related to the specific object, helping the analyst to better understand the context and progression of risk within the environment."
    },
    {
        "question": "A Risk Rule generates events on Suspicious Cloud Share Activity and regularly contributes to confirmed incidents from Risk Notables. An analyst realizes the raw logs these events are generated from contain information which helps them determine what might be malicious. What should they ask their engineer for to make their analysis easier?",
        "answers": [
          { "text": "Create a field extraction for this information.", "correct": false },
          { "text": "Add this information to the risk_message.", "correct": true },
          { "text": "Create another detection for this information.", "correct": false },
          { "text": "Allowlist more events based on this information.", "correct": false }
        ],
        "explanation": "ANSWER: B \n The risk_message field in Splunk's Risk-Based Alerting framework provides context about why a risk score was assigned to an object or event. By asking the engineer to include additional information from the raw logs in the risk_message, the analyst can have easier access to the relevant data needed to determine whether the activity is malicious, without having to repeatedly search through the raw logs. This improves the efficiency and effectiveness of their analysis."
    },
    {
        "question": "What device typically sits at a network perimeter to detect command and control and other potentially suspicious traffic?",
        "answers": [
          { "text": "Host-based firewall", "correct": false },
          { "text": "Web proxy", "correct": false },
          { "text": "Endpoint Detection and Response", "correct": false },
          { "text": "Intrusion Detection System", "correct": true }
        ],
        "explanation": "ANSWER: D \n An Intrusion Detection System (IDS) typically sits at the network perimeter or other key points within a network to monitor and analyze traffic for potentially suspicious activities, such as command and control (C2) traffic, unauthorized access, or other signs of malicious behavior. An IDS inspects network packets and generates alerts for detected threats, providing visibility into anomalous or potentially harmful traffic entering or leaving the network."
    },
    {
        "question": "Upon investigating a report of a web server becoming unavailable, the security analyst finds that the web server’s access log has the same log entry millions of times: 147.186.119.200 - - [28/Jul/2023:12:04:13 -0300] 'GET /login/ HTTP/1.0' 200 3733 \n What kind of attack is occurring?",
        "answers": [
          { "text": "Denial of Service Attack", "correct": true },
          { "text": "Distributed Denial of Service Attack", "correct": false },
          { "text": "Cross-Site Scripting Attack", "correct": false },
          { "text": "Database Injection Attack", "correct": false }
        ],
        "explanation": "ANSWER: A \n The repeated identical log entry suggests that a single IP address (147.186.119.200) is sending a high volume of requests (GET /login/ HTTP/1.0) to the web server. This overwhelming traffic causes the server to become unavailable, which is characteristic of a Denial of Service (DoS) Attack. Unlike a Distributed Denial of Service (DDoS) Attack, which involves multiple sources, this attack appears to come from a single source, as evidenced by the same IP address repeatedly logged"
    },
    {
        "question": "According to David Bianco's Pyramid of Pain, which indicator type is least effective when used in continuous monitoring?",
        "answers": [
          { "text": "Domain names", "correct": false },
          { "text": "TTPs", "correct": false },
          { "text": "Network/Host artifacts", "correct": false },
          { "text": "Hash values", "correct": true }
        ],
        "explanation": "ANSWER: D \n In David Bianco's Pyramid of Pain, hash values are considered the least effective indicator type for continuous monitoring because they are easy for adversaries to change. A minor modification to a file or payload alters its hash, rendering the indicator ineffective for detecting similar threats. On the other hand, indicators like Tactics, Techniques, and Procedures (TTPs) are at the top of the pyramid and are much harder for adversaries to modify, making them more effective for threat detection and response."
    },
    {
        "question": "An analysis of an organization’s security posture determined that a particular asset is at risk and a new process or solution should be implemented to protect it. Typically, who would be in charge of implementing the new process or solution that was selected?",
        "answers": [
          { "text": "Security Architect", "correct": false },
          { "text": "SOC Manager", "correct": false },
          { "text": "Security Engineer", "correct": true },
          { "text": "Security Analyst", "correct": false }
        ],
        "explanation": "ANSWER: C \n The Security Engineer is typically responsible for implementing new processes or solutions to protect assets in an organization. Their role involves deploying, configuring, and maintaining security technologies, as well as ensuring that these solutions integrate effectively with the organization's infrastructure. While other roles (e.g., Security Architect or SOC Manager) may be involved in designing the strategy or overseeing operations, the hands-on implementation of selected security measures is primarily the responsibility of the Security Engineer."
    },
    {
        "question": "Which of the following is a correct Splunk search that will return results in the most performant way?",
        "answers": [
          { "text": "index=foo host=i-478619733 | stats range(_time) as duration by src_ip | bin duration span=5min | stats count by duration, host", "correct": true },
          { "text": " | stats range(_time) as duration by src_ip | index=foo host=i-478619733 | bin duration span=5min | stats count by duration, host", "correct": false },
          { "text": "index=foo host=i-478619733 | transaction src_ip |stats count by host", "correct": false },
          { "text": "index=foo | transaction src_ip |stats count by host | search host=i-478619733", "correct": false }
        ],
        "explanation": "ANSWER: A \n *This search is the most performant because:\n 1.Index-time filtering: The search starts with `index=foo` and `host=i-478619733`, which applies index-time constraints. This reduces the dataset as early as possible, which is crucial for performance. Filtering at the beginning ensures that Splunk only retrieves relevant events from storage.\n 2.Efficient use of commands: The `stats` command is computationally efficient and is used here instead of more resource-intensive commands like `transaction`. The `transaction` command is known to be heavy on resources and should be avoided unless absolutely necessary.\n 3.Logical flow: The sequence of commands (`stats`, `bin`, `stats`) processes the data in a logical and efficient manner. By binning and summarizing data before further aggregation, it minimizes intermediate data size and computational overhead \n \n \n Why the other options are less efficient:* \n B: Starts with `stats` before filtering with `index=foo`, which means Splunk processes the entire dataset unnecessarily before applying the index constraint. \n C and D: Both use `transaction`, which is resource-intensive and should be avoided for performance reasons when `stats` can achieve the same outcome. Additionally, D applies filtering (`host=i-478619733`) after the `transaction` and other processing, making it less efficient."
    },
    {
        "question": "There are many resources for assisting with SPL and configuration questions. Which of the following resources feature community-sourced answers?",
        "answers": [
          { "text": "Splunk Answers", "correct": true },
          { "text": "Splunk Lantern", "correct": false },
          { "text": "Splunk Guidebook", "correct": false },
          { "text": "Splunk Documentation", "correct": false }
        ],
        "explanation": "ANSWER: A \n Splunk Answers is a community-driven platform where Splunk users, partners, and employees contribute by answering questions about SPL (Search Processing Language), configurations, troubleshooting, and other topics. It allows users to tap into the collective knowledge and experiences of the Splunk community. \n\n Why the others are incorrect: \n B. Splunk Lantern: Provides best practices, use case guidance, and pre-written searches, but it is curated by Splunk and not community-sourced. \n C. Splunk Guidebook: Does not exist as an official resource. \n D. Splunk Documentation: Official product documentation written and maintained by Splunk, not community-sourced."
    },
    {
        "question": "A successful Continuous Monitoring initiative involves the entire organization. When an analyst discovers the need for more context or additional information, perhaps from additional data sources or altered correlation rules, to what role would this request generally escalate?",
        "answers": [
          { "text": "SOC Manager", "correct": false },
          { "text": "Security Analyst", "correct": false },
          { "text": "Security Engineer", "correct": true },
          { "text": "Security Architect", "correct": false }
        ],
        "explanation": "ANSWER: C \n  When an analyst identifies the need for additional context, new data sources, or changes to correlation rules, the request is typically escalated to the Security Engineer. The Security Engineer is responsible for managing and configuring the security tools and ensuring the appropriate data sources are integrated into the monitoring environment. They handle tasks such as onboarding new logs, refining correlation rules, and ensuring the system is optimized to provide the required context for analysis. \n \n Role Clarifications: \n SOC Manager: Oversees the Security Operations Center (SOC) and focuses on staffing, processes, and high-level strategy, not technical configurations. \n Security Analyst: Typically responsible for investigating alerts and incidents, but they escalate technical changes or data integrations to the Security Engineer. \n Security Architect: Designs the overall security strategy and infrastructure but is not typically involved in day-to-day changes to monitoring or tooling configurations."
    },
    {
        "question": "Splunk Enterprise Security has numerous frameworks to create correlations, integrate threat intelligence, and provide a workflow for investigations. Which framework raises the threat profile of individuals or assets to allow identification of people or devices that perform an unusual amount of suspicious activities?",
        "answers": [
          { "text": "Threat Intelligence Framework", "correct": false },
          { "text": "Risk Framework", "correct": true },
          { "text": "Notable Event Framework", "correct": false },
          { "text": "Asset and Identity Framework", "correct": false }
        ],
        "explanation": "ANSWER: B \n The Risk Framework in Splunk Enterprise Security is used to raise the threat profile of individuals or assets by assigning risk scores based on their behavior and activities. It aggregates risk events and calculates risk scores to highlight entities (e.g., users, devices, or IPs) that exhibit unusual or suspicious behavior. This enables analysts to prioritize investigations by identifying high-risk individuals or assets that require further scrutiny."
    },
    {
        "question": "While the top command is utilized to find the most common values contained within a field, a Cyber Defense Analyst hunts for anomalies. Which of the following Splunk commands returns the least common values?",
        "answers": [
          { "text": "least", "correct": false },
          { "text": "uncommon", "correct": false },
          { "text": "rare", "correct": true },
          { "text": "base", "correct": false }
        ],
        "explanation": "ANSWER: C \n In Splunk, the rare command is used to identify the least common values in a field, making it valuable for anomaly detection. It is the counterpart to the top command, which identifies the most common values. By using rare, a Cyber Defense Analyst can focus on unusual or infrequent patterns that may indicate anomalies or suspicious activities in the data."
    },
    {
        "question": "The Lockheed Martin Cyber Kill Chain breaks an attack lifecycle into several stages. A threat actor modified the registry on a compromised Windows system to ensure that their malware would automatically run at boot time. Into which phase of the Kill Chain would this fall?",
        "answers": [
          { "text": "Act on Objectives", "correct": false },
          { "text": "Exploitation", "correct": false },
          { "text": "Delivery", "correct": false },
          { "text": "Installation", "correct": true }
        ],
        "explanation": "ANSWER: D \n In the Lockheed Martin Cyber Kill Chain, the Installation phase involves the attacker establishing persistence on the compromised system. Modifying the Windows registry to ensure malware runs automatically at boot time is a classic example of a persistence mechanism, which is a key activity in the Installation phase. This step ensures that the malware remains active even after a system reboot or user logoff, enabling the attacker to maintain control of the system."
    },
    {
        "question": "A Risk Notable Event has been triggered in Splunk Enterprise Security, an analyst investigates the alert, and determines it is a false positive. What metric would be used to define the time between alert creation and close of the event?",
        "answers": [
          { "text": "MTTR (Mean Time to Respond)", "correct": true },
          { "text": "MTBF (Mean Time Between Failures)", "correct": false },
          { "text": "MTTA (Mean Time to Acknowledge)", "correct": false },
          { "text": "MTTD (Mean Time to Detect)", "correct": false }
        ],
        "explanation": "ANSWER: A \n MTTR (Mean Time to Respond) measures the average time taken to investigate and close an alert or incident, whether it is valid or a false positive. In the context of a Risk Notable Event in Splunk Enterprise Security, MTTR would represent the time elapsed between the creation of the alert and the analyst resolving it (e.g., determining it is a false positive or taking appropriate action). \n\n Why the others are incorrect: \n B. MTBF (Mean Time Between Failures): Used in reliability engineering to measure the average time between system or component failures, not applicable to alert handling. \n C. MTTA (Mean Time to Acknowledge): Measures the time taken to acknowledge an alert, not to resolve it. \n D. MTTD (Mean Time to Detect): Refers to the time taken to detect an issue or anomaly, which occurs before the alert is created."
    },
    {
        "question": "An analyst needs to create a new field at search time. Which Splunk command will dynamically extract additional fields as part of a Search pipeline?",
        "answers": [
          { "text": "rex", "correct": true },
          { "text": "fields", "correct": false },
          { "text": "regex", "correct": false },
          { "text": "eval", "correct": false }
        ],
        "explanation": "ANSWER: A \n The rex command in Splunk is used to dynamically extract fields from raw event data at search time using regular expressions. It allows analysts to define patterns for extracting data into new fields as part of a search pipeline. This is particularly useful when the desired field is not pre-indexed or explicitly defined in the source data."
    },
    {
        "question": "Which of the following is considered Personal Data under GDPR?",
        "answers": [
          { "text": "The birth date of an unidentified user.", "correct": false },
          { "text": "An individual’s address including their first and last name.", "correct": true },
          { "text": "The name of a deceased individual.", "correct": false },
          { "text": "A company’s registration number.", "correct": false }
        ],
        "explanation": "ANSWER: C \n Under the General Data Protection Regulation (GDPR), Personal Data is defined as any information relating to an identified or identifiable natural person. An individual's address combined with their first and last name qualifies as personal data because it can directly identify the person."
    },
    {
        "question": "What goal of an Advanced Persistent Threat (APT) group aims to disrupt or damage on behalf of a cause?",
        "answers": [
          { "text": "Hacktivism", "correct": true },
          { "text": "Cyber espionage", "correct": false },
          { "text": "Financial gain", "correct": false },
          { "text": "Prestige", "correct": false }
        ],
        "explanation": "ANSWER: A \n Hacktivism refers to cyber activities conducted by threat actors with the goal of disrupting or damaging systems, often as a form of protest or to advance a specific cause or ideology. Advanced Persistent Threat (APT) groups engaging in hacktivism typically aim to make a political, social, or ideological statement through their actions."
    },
    {
        "question": "A Cyber Threat Intelligence (CTI) team produces a report detailing a specific threat actor’s typical behaviors and intent. This would be an example of what type of intelligence?",
        "answers": [
          { "text": "Operational", "correct": false },
          { "text": "Executive", "correct": false },
          { "text": "Tactical", "correct": false },
          { "text": "Strategic", "correct": true }
        ],
        "explanation": "ANSWER: D \n A report detailing a specific threat actor's typical behaviors and intent represents Strategic Intelligence, which focuses on the overarching goals, motivations, and long-term behaviors of threat actors. This type of intelligence is intended to provide high-level insights to inform decision-makers about potential threats and their implications for an organization."
    },
    {
        "question": "An organization is using Risk-Based Alerting (RBA). During the past few days, a user account generated multiple risk observations. Splunk refers to this account as what type of entity?",
        "answers": [
          { "text": "Risk Factor", "correct": false },
          { "text": "Risk Index", "correct": false },
          { "text": "Risk Analysis", "correct": false },
          { "text": "Risk Object", "correct": true }
        ],
        "explanation": "ANSWER: D \n In Splunk's Risk-Based Alerting (RBA) framework, a Risk Object refers to the entity (such as a user account, host, or IP address) that is associated with risk observations or events. In this case, the user account that generated multiple risk observations is identified as the Risk Object. Risk scores are aggregated for Risk Objects to help prioritize investigations and identify high-risk entities within an organization."
    },
    {
        "question": "When searching in Splunk, which of the following SPL commands can be used to run a subsearch across every field in a wildcard field list?",
        "answers": [
          { "text": "foreach", "correct": true },
          { "text": "rex", "correct": false },
          { "text": "makeresults", "correct": false },
          { "text": "transaction", "correct": false }
        ],
        "explanation": "ANSWER: A \n The foreach command in Splunk allows you to iterate over a list of fields (such as a wildcard field list) and apply a specified operation to each field. This is useful when you need to perform actions, like running subsearches, transformations, or calculations, across all fields that match a certain pattern or wildcard."
    },
    {
        "question": "How are Notable Events configured in Splunk Enterprise Security?",
        "answers": [
          { "text": "During an investigation.", "correct": false },
          { "text": "As part of an audit.", "correct": false },
          { "text": "Via an Adaptive Response Action in a regular search.", "correct": false },
          { "text": "Via an Adaptive Response Action in a correlation search.", "correct": true }
        ],
        "explanation": "ANSWER: D \n In Splunk Enterprise Security, Notable Events are configured through Adaptive Response Actions within correlation searches. When setting up a correlation search, you can define specific criteria and configure the search to trigger a Notable Event when those criteria are met. This process allows security analysts to automatically generate alerts (Notable Events) based on patterns, anomalies, or suspicious activity detected in the environment."
    },
    {
        "question": "An analyst is investigating a network alert for suspected lateral movement from one Windows host to another Windows host. According to Splunk CIM documentation, the IP address of the host from which the attacker is moving would be in which field?",
        "answers": [
          { "text": "host", "correct": false },
          { "text": "dest", "correct": false },
          { "text": "src_nt_host", "correct": false },
          { "text": "src_ip", "correct": true }
        ],
        "explanation": "ANSWER: D \n According to Splunk's Common Information Model (CIM) documentation, the src_ip field represents the IP address of the source host, which, in this case, would be the host from which the attacker is moving during suspected lateral movement."
    },
    {
        "question": "Which of the following data sources can be used to discover unusual communication within an organization’s network?",
        "answers": [
          { "text": "EDS", "correct": false },
          { "text": "NetFlow", "correct": true },
          { "text": "Email", "correct": false },
          { "text": "IAM", "correct": false }
        ],
        "explanation": "ANSWER: B \n NetFlow is a network protocol that collects and analyzes metadata about network traffic, such as source and destination IPs, ports, protocols, and traffic volumes. By analyzing NetFlow data, unusual or anomalous communication patterns within an organization's network can be identified, such as unexpected connections between internal hosts or communication with suspicious external IP addresses"
    },
    {
        "question": "When threat hunting for outliers in Splunk, which of the following SPL pipelines would filter for users with over a thousand occurrences?",
        "answers": [
          { "text": "| sort by user | where count > 1000", "correct": false },
          { "text": "| stats count by user | where count > 1000 | sort - count", "correct": true },
          { "text": "| top user", "correct": false },
          { "text": "| stats count(user) | sort - count | where count > 1000", "correct": false }
        ],
        "explanation": "ANSWER: B \n This SPL pipeline filters for users with more than 1,000 occurrences, making it suitable for threat hunting to identify outliers: \n 1.`stats count by user`:** Counts the number of occurrences for each user. \n 2.`where count > 1000`: Filters the results to include only users with a count greater than 1,000. \n 3.`sort - count`: Sorts the filtered results in descending order by the count for easier review of the most frequent outliers."
    },
    {
        "question": "The United States Department of Defense (DoD) requires all government contractors to provide adequate security safeguards referenced in National Institute of Standards and Technology (NIST) 800-171. All DoD contractors must continually reassess, monitor, and track complianceto be able to do business with the US government. Which feature of Splunk Enterprise Security provides an analyst context for the correlation search mapping to the specific NIST guidelines?",
        "answers": [
          { "text": "Comments", "correct": false },
          { "text": "Notes", "correct": false },
          { "text": "Annotations", "correct": true },
          { "text": "Framework mapping", "correct": false }
        ],
        "explanation": "ANSWER: C \n In Splunk Enterprise Security, Annotations provide context by mapping correlation searches to specific guidelines, standards, or frameworks such as NIST 800-171. Annotations help analysts understand how a specific correlation search aligns with regulatory requirements or security frameworks, enabling them to track compliance and address gaps more effectively."
    },
    {
        "question": "An analyst is investigating the number of failed login attempts by IP address. Which SPL command can be used to create a temporary table containing the number of failed login attempts by IP address over a specific time period?",
        "answers": [
          { "text": "index=security_logs eventtype=failed_login | eval count as failed_attempts by src_ip | sort -failed_attempts", "correct": false },
          { "text": "index=security_logs eventtype=failed_login | transaction count as failed_attempts by src_ip | sort -failed_attempts", "correct": false },
          { "text": "index=security_logs eventtype=failed_login | stats count as failed_attempts by src_ip | sort -failed_attempts", "correct": true },
          { "text": "index=security_logs eventtype=failed_login | sum count as failed_attempts by src_ip | sort -failed_attempts", "correct": false }
        ],
        "explanation": "ANSWER: C \n "
    },
    {
        "question": "The field file_acl contains access controls associated with files affected by an event. In which data model would an analyst find this field?",
        "answers": [
          { "text": "Malware", "correct": false },
          { "text": "Alerts", "correct": false },
          { "text": "Vulnerabilities", "correct": false },
          { "text": "Endpoint", "correct": true }
        ],
        "explanation": "ANSWER: D \n The file_acl field, which contains access controls associated with files, is part of the Endpoint data model in Splunk Enterprise Security. The Endpoint data model is designed to capture and standardize information about file system activities, process activities, and other endpoint-related events, including file access controls. This makes it the appropriate data model for events involving file access permissions or changes."
    },
    {
        "question": "A threat hunter generates a report containing the list of users who have logged in to a particular database during the last 6 months, along with the number of times they have each authenticated. They sort this list and remove any user names who have logged in more than 6 times. The remaining names represent the users who rarely log in, as their activity is more suspicious. The hunter examines each of these rare logins in detail. This is an example of what type of threat-hunting technique?",
        "answers": [
          { "text": "Least Frequency of Occurrence Analysis", "correct": true },
          { "text": "Co-Occurrence Analysis", "correct": false },
          { "text": "Time Series Analysis", "correct": false },
          { "text": "Outlier Frequency Analysis", "correct": false }
        ],
        "explanation": "ANSWER: A \n This is an example of Least Frequency of Occurrence Analysis, a threat-hunting technique that focuses on identifying entities (e.g., users, IPs, devices) that appear less frequently in a dataset. By removing users who logged in more than six times, the hunter isolates those with rare login activity, which may indicate anomalous or suspicious behavior requiring closer examination. This approach is particularly useful in detecting potential insider threats or compromised accounts."
    },
    {
        "question": "What is the main difference between hypothesis-driven and data-driven Threat Hunting?",
        "answers": [
          { "text": "Data-driven hunts always require more data to search through than hypothesis-driven hunts.", "correct": false },
          { "text": "Data-driven hunting tries to uncover activity within an existing data set, hypothesis-driven hunting begins with a potential activity that the hunter thinks may be happening.", "correct": true },
          { "text": "Hypothesis-driven hunts are typically executed on newly ingested data sources, while data-driven hunts are not.", "correct": false },
          { "text": "Hypothesis-driven hunting tries to uncover activity within an existing data set, data-driven hunting begins with an activity that the hunter thinks may be happening.", "correct": false }
        ],
        "explanation": "ANSWER: B \n "
    },
    {
        "question": "The Security Operations Center (SOC) manager is interested in creating a new dashboard for typosquatting after a successful campaign against a group of senior executives. Which existing ES dashboard could be used as a starting point to create a custom dashboard?",
        "answers": [
          { "text": "IAM Activity", "correct": false },
          { "text": "Malware Center", "correct": false },
          { "text": "Access Anomalies", "correct": false },
          { "text": "New Domain Analysis", "correct": true }
        ],
        "explanation": "ANSWER: D \n The New Domain Analysis dashboard in Splunk Enterprise Security is a suitable starting point for creating a custom dashboard for typosquatting detection. Typosquatting often involves registering domains that are visually similar to legitimate domains, and the New Domain Analysis dashboard focuses on identifying unusual or newly observed domains that could be used in phishing or impersonation attacks. This aligns well with the SOC manager's objective of analyzing typosquatting activity."
    },
    {
        "question": "What is the main difference between a DDoS and a DoS attack?",
        "answers": [
          { "text": "A DDoS attack is a type of physical attack, while a DoS attack is a type of cyberattack.", "correct": false },
          { "text": "A DDoS attack uses a single source to target a single system, while a DoS attack uses multiple sources to target multiple systems.", "correct": false },
          { "text": "A DDoS attack uses multiple sources to target a single system, while a DoS attack uses a single source to target a single or multiple systems.", "correct": true },
          { "text": "A DDoS attack uses a single source to target multiple systems, while a DoS attack uses multiple sources to target a single system", "correct": false }
        ],
        "explanation": "ANSWER: C \n "
    },
    {
        "question": "A Cyber Threat Intelligence (CTI) team delivers a briefing to the CISO detailing their view of the threat landscape the organization faces. This is an example of what type of Threat Intelligence?",
        "answers": [
          { "text": "Tactical", "correct": false },
          { "text": "Strategic", "correct": true },
          { "text": "Operational", "correct": false },
          { "text": "Executive", "correct": false }
        ],
        "explanation": "ANSWER: B \n A briefing delivered to the Chief Information Security Officer (CISO) detailing the threat landscape focuses on high-level insights about risks, adversary motives, and trends in the cybersecurity environment. This aligns with Strategic Threat Intelligence, which provides long-term, big-picture analysis to support decision-making and align security strategies with the organization's goals."
    },
    {
        "question": "An analyst is examining the logs for a web application’s login form. They see thousands of failed logon attempts using various usernames and passwords. Internet research indicates that these credentials may have been compiled by combining account information from several recent data breaches. Which type of attack would this be an example of?",
        "answers": [
          { "text": "Credential sniffing", "correct": false },
          { "text": "Credential cracking", "correct": false },
          { "text": "Password spraying", "correct": false },
          { "text": "Credential stuffing", "correct": true }
        ],
        "explanation": "ANSWER: D \n Credential stuffing is an attack where previously stolen usernames and passwords from data breaches are used in bulk to attempt unauthorized logins on a system. Attackers rely on users reusing passwords across multiple services. The analyst's observation of thousands of failed login attempts using various combinations of usernames and passwords aligns with this type of attack."
    },
    {
        "question": "An analysis of an organization’s security posture determined that a particular asset is at risk and a new process or solution should be implemented to protect it. Typically, who would be in charge of designing the new process and selecting the required tools to implement it?",
        "answers": [
          { "text": "SOC Manager", "correct": false },
          { "text": "Security Engineer", "correct": false },
          { "text": "Security Architect", "correct": true },
          { "text": "Security Analyst", "correct": false }
        ],
        "explanation": "ANSWER: C \n The Security Architect is responsible for designing security processes and selecting tools to address risks to an organization’s assets. This role focuses on creating comprehensive security strategies and ensuring that chosen solutions align with the organization's overall security goals and architecture. Security Architects bridge the gap between identifying risks and implementing solutions."
    },
    {
      "question": "After discovering some events that were missed in an initial investigation, an analyst determines this is because some events have an empty src field. Instead, the required data is often captured in another field called machine_name. What SPL could they use to find all relevant events across either field until the field extraction is fixed?",
      "answers": [
        { "text": "| eval src = coalesce(src,machine_name)", "correct": true },
        { "text": "| eval src = src + machine_name", "correct": false },
        { "text": "| eval src = src . machine_name", "correct": false },
        { "text": "| eval src = tostring(machine_name)", "correct": false }
      ],
      "explanation": "ANSWER: A \n The coalesce function in Splunk is used to return the first non-empty value from a list of fields. By using eval src = coalesce(src, machine_name), the analyst ensures that the src field is populated with its original value if present, or the value from machine_name if src is empty. This approach effectively consolidates the data for the analysis while waiting for the field extraction issue to be fixed"
    },
    {
      "question": "An analyst would like to test how certain Splunk SPL commands work against a small set of data. What command should start the search pipeline if they wanted to create their own data instead of utilizing data contained within Splunk?",
      "answers": [
        { "text": "makeresults", "correct": true },
        { "text": "rename", "correct": false },
        { "text": "eval", "correct": false },
        { "text": "stats", "correct": false }
      ],
      "explanation": "ANSWER: A \n The makeresults command in Splunk is used to create a single, empty event that can be populated with custom fields and values. It is particularly useful for testing and experimenting with SPL commands without relying on existing data in Splunk. Analysts can use makeresults to simulate data and build out or test SPL queries in a controlled environment."
    },
    {
      "question": "What is the following step-by-step description an example of?\n 1.The attacker devises a non-default beacon profile with Cobalt Strike and embeds this within a document.\n 2.The attacker creates a unique email with the malicious document based on extensive research about their target.\n 3.When the victim opens this document, a C2 channel is established to the attacker’s temporary infrastructure on a compromised website.",
      "answers": [
        { "text": "Tactic", "correct": false },
        { "text": "Policy", "correct": false },
        { "text": "Procedure", "correct": false },
        { "text": "Technique", "correct": true }
      ],
      "explanation": "ANSWER: D \n The described step-by-step example outlines a Technique, which refers to a specific method or way that attackers achieve a particular objective during an attack. In this case, the example demonstrates a specific method of establishing a Command and Control (C2) channel using Cobalt Strike through a malicious document sent via email. This is consistent with the definition of a Technique in frameworks like MITRE ATT&CK."
    },
    {
      "question": "Which of the following is a best practice when creating performant searches within Splunk?",
      "answers": [
        { "text": "Utilize the transaction command to aggregate data for faster analysis.", "correct": false },
        { "text": "Utilize Aggregating commands to ensure all data is available prior to Streaming commands.", "correct": false },
        { "text": "Utilize specific fields to return only the data that is required.", "correct": true },
        { "text": "Utilize multiple wildcards across fields to ensure returned data is complete and available.", "correct": false }
      ],
      "explanation": "ANSWER: C \n Using specific fields in Splunk searches ensures that only the necessary data is returned, reducing the amount of data processed and significantly improving search performance. This best practice minimizes resource consumption and enhances the speed of searches."
    },
    {
      "question": "Which pre-packaged app delivers security content and detections on a regular, ongoing basis for Enterprise Security and SOAR?",
      "answers": [
        { "text": "SSE", "correct": false },
        { "text": "ESCU", "correct": true },
        { "text": "Threat Hunting", "correct": false },
        { "text": "InfoSec", "correct": false }
      ],
      "explanation": "ANSWER: B \n ESCU (Enterprise Security Content Update) is a pre-packaged app for Splunk Enterprise Security that provides regularly updated security content, such as detection rules, dashboards, and threat intelligence. ESCU is specifically designed to enhance the capabilities of Enterprise Security (ES) and Splunk SOAR by delivering new detections and content aligned with the latest security threats and attack techniques, including frameworks like MITRE ATT&CK."
    },
    {
      "question": "Which search command allows an analyst to match whatever is inside the parentheses as a single term in the index, even if it contains characters that are usually recognized as minor breakers such as periods or underscores?",
      "answers": [
        { "text": "CASE()", "correct": false },
        { "text": "LIKE()", "correct": false },
        { "text": "FORMAT()", "correct": false },
        { "text": "TERM()", "correct": true }
      ],
      "explanation": "ANSWER: D \n The TERM() function in Splunk is used to treat whatever is inside the parentheses as a single term, even if it includes special characters like periods (.) or underscores (_). This is particularly useful for searching terms that might otherwise be broken into smaller tokens by Splunk’s default indexing and search behavior"
    },
    {
      "question": "Which field is automatically added to search results when assets are properly defined and enabled in Splunk Enterprise Security?",
      "answers": [
        { "text": "asset_category", "correct": false },
        { "text": "src_ip", "correct": false },
        { "text": "src_category", "correct": true },
        { "text": "user", "correct": false }
      ],
      "explanation": "ANSWER: C \n In Splunk Enterprise Security, when assets are properly defined and enabled in the Asset and Identity Framework, the src_category field is automatically added to search results. This field categorizes the asset based on its role or purpose within the organization, such as 'web server' or 'database server.' It provides valuable context for analyzing events and prioritizing security investigations"
    },
    {
        "question": "An IDS signature is designed to detect and alert on logins to a certain server, but only if they occur from 6:00 PM - 6:00 AM. If no IDS alerts occur in this window, but the signature is known to be correct, this would be an example of what?",
        "answers": [
          { "text": "A True Negative", "correct": true },
          { "text": "A True Positive", "correct": false },
          { "text": "A False Negative", "correct": false },
          { "text": "A False Positive", "correct": false }
        ],
        "explanation": "ANSWER: A \n A True Negative occurs when no alert is generated because no suspicious or malicious activity matching the detection criteria has occurred. In this scenario, if no logins to the server occurred between 6:00 PM and 6:00 AM (the time window specified in the IDS signature), the lack of alerts is the correct outcome, making it a True Negative"
    },
    {
      "question": "Which of the following is not a component of the Splunk Security Content library (ESCU, SSE)?",
      "answers": [
        { "text": "Dashboards", "correct": false},
        { "text": "Reports", "correct": false },
        { "text": "Correlation searches", "correct": false },
        { "text": "Validated architectures", "correct": true }
      ],
      "explanation": "ANSWER: D \n The Splunk Security Content library (provided through apps like ESCU and SSE) includes components such as dashboards, reports, and correlation searches to help security teams detect, investigate, and respond to threats. These components provide practical tools and detections aligned with frameworks like MITRE ATT&CK."
    },
    {
      "question": "The eval SPL expression supports many types of functions. Which of these function categories is not valid with eval?",
      "answers": [
        { "text": "JSON functions", "correct": false },
        { "text": "Text functions", "correct": false },
        { "text": "Comparison and Conditional functions", "correct": false },
        { "text": "Threat functions", "correct": true }
      ],
      "explanation": "ANSWER: D \n There is no category called Threat functions in the eval command. Threat analysis and security-specific operations in Splunk are handled through correlation searches, security frameworks, or custom searches, not directly via eval"
    },
    {
      "question": "Which of the following is a tactic used by attackers, rather than a technique?",
      "answers": [
        { "text": "Gathering information about a target.", "correct": true },
        { "text": "Establishing persistence with a scheduled task.", "correct": false },
        { "text": "Using a phishing email to gain initial access.", "correct": false },
        { "text": "Escalating privileges via UAC bypass.", "correct": false }
      ],
      "explanation": "ANSWER: A \n In cybersecurity frameworks such as MITRE ATT&CK, a tactic represents the goal or objective that an attacker is trying to achieve. Gathering information about a target aligns with the Reconnaissance tactic, where the attacker seeks information about the target environment to plan further actions.\n The other options are examples of techniques, which describe specific ways attackers achieve their goals (tactics):\n B. Establishing persistence with a scheduled task: This is a technique under the Persistence tactic. \n C. Using a phishing email to gain initial access: This is a technique under the Initial Access tactic. \n D. Escalating privileges via UAC bypass: This is a technique under the Privilege Escalation tactic."
    },
    {
      "question": "Which stage of continuous monitoring involves adding data, creating detections, and building drilldowns?",
      "answers": [
        { "text": "Implement and Collect", "correct": true },
        { "text": "Establish and Architect", "correct": false },
        { "text": "Respond and Review", "correct": false },
        { "text": "Analyze and Report", "correct": false }
      ],
      "explanation": "ANSWER: A \n The Implement and Collect stage of continuous monitoring focuses on gathering relevant data sources, creating detections, and developing drilldowns for further analysis. This phase is crucial for setting up monitoring capabilities, ensuring that the system collects appropriate data, and building detection rules to identify anomalies or potential security threats. \n B. Establish and Architect: This phase focuses on planning and designing the architecture for continuous monitoring, including tools and frameworks. \n C. Respond and Review: This stage involves addressing incidents, reviewing findings, and making improvements based on monitoring results. \n D. Analyze and Report: In this phase, collected data and detections are analyzed, and insights are reported to stakeholders for decision-making."
    },
    {
      "question": "An analyst is investigating how an attacker successfully performs a brute-force attack to gain a foothold into an organizations systems. In the course of the investigation the analyst determines that the reason no alerts were generated is because the detection searches were configured to run against Windows data only and excluding any Linux data. This is an example of what?",
      "answers": [
        { "text": "A True Positive", "correct": false },
        { "text": "A True Negative", "correct": false },
        { "text": "A False Negative", "correct": true },
        { "text": "A False Positive", "correct": false }
      ],
      "explanation": "ANSWER: D \n A False Negative occurs when a detection mechanism fails to identify and alert on malicious activity that is actually happening. In this case, the brute-force attack was successful, but no alerts were generated because the detection searches were incorrectly configured to exclude Linux data. This misconfiguration resulted in the attack going unnoticed, making it a False Negative. Why the other options are incorrect:\n A. A True Positive: A True Positive is when an alert is correctly generated for malicious activity. In this case, no alert was generated. \n B. A True Negative: A True Negative occurs when there is no malicious activity, and no alert is generated. Here, malicious activity did occur. \n D. A False Positive: A False Positive occurs when an alert is triggered for benign activity. In this case, there was no alert."
    },
    {
      "question": "An analyst investigates an IDS alert and confirms suspicious traffic to a known malicious IP. What Enterprise Security data model would they use to investigate which process initiated the network connection?",
      "answers": [
        { "text": "Endpoint", "correct": true },
        { "text": "Authentication", "correct": false },
        { "text": "Network traffic", "correct": false },
        { "text": "Web", "correct": false }
      ],
      "explanation": "ANSWER: A \n The Endpoint data model in Splunk Enterprise Security is used to analyze and investigate process activities on endpoints, such as which process initiated a network connection. This data model includes fields related to processes, file operations, and command executions, making it the appropriate choice for determining the process responsible for generating the suspicious traffic."
    },
    {
      "question": "Which of the following is a best practice for searching in Splunk?",
      "answers": [
        { "text": "Streaming commands run before aggregating commands in the Search pipeline.", "correct": true },
        { "text": "Raw word searches should contain multiple wildcards to ensure all edge cases are covered.", "correct": false },
        { "text": "Limit fields returned from the search utilizing the table command.", "correct": false },
        { "text": "Searching over All Time ensures that all relevant data is returned.", "correct": false }
      ],
      "explanation": "ANSWER: A \n In Splunk, streaming commands (like eval, where, and rex) operate on events as they are streamed from the index. These commands are computationally efficient and should run before aggregating commands (like stats, chart, and timechart), which summarize or group data. Running streaming commands first reduces the amount of data passed to the aggregating commands, improving search performance."
    },
    {
      "question": "While testing the dynamic removal of credit card numbers, an analyst lands on using the rex command. What mode needs to be set to in order to replace the defined values with X? \n | makeresults \n| eval ccnumber='511388720478619733' \n | rex field=ccnumber mode=??? 's/(\\d{4}-){3)/XXXX-XXXX-XXXX-/g' \nPlease assume that the above rex command is correctly written.",
      "answers": [
        { "text": "sed", "correct": true },
        { "text": "replace", "correct": false },
        { "text": "mask", "correct": false },
        { "text": "substitute", "correct": false }
      ],
      "explanation": "ANSWER: A \n In Splunk, the rex command supports the mode=sed option to perform string replacements or substitutions using a regular expression. This allows you to dynamically modify values, such as replacing parts of a credit card number with X to mask sensitive data. \n Why the other options are incorrect: \n B. replace: Not a valid mode for the rex command. \n C. mask: No such mode exists in the rex command. \n D. substitute: Splunk does not use substitute as a mode for text replacement; sed is the correct syntax for such operations."
    },
    {
      "question": "Which of the following use cases is best suited to be a Splunk SOAR Playbook?",
      "answers": [
        { "text": "Forming hypothesis for Threat Hunting", "correct": false },
        { "text": "Visualizing complex datasets.", "correct": false },
        { "text": "Creating persistent field extractions", "correct": false },
        { "text": "Taking containment action on a compromised host", "correct": true }
      ],
      "explanation": "ANSWER: D \n Splunk SOAR (Security Orchestration, Automation, and Response) is designed to automate and orchestrate security tasks, such as responding to incidents. Taking containment action on a compromised host (e.g., isolating the host, disabling a user account, or blocking an IP) is a perfect use case for a SOAR Playbook because it automates the response process, reducing manual intervention and speeding up incident mitigation."
    },
    {
      "question": "Which of the following is not considered an Indicator of Compromise (IOC)?",
      "answers": [
        { "text": "A specific domain that is utilized for phishing", "correct": false },
        { "text": "A specific IP address used in a cyberattack.", "correct": false },
        { "text": "A specific file hash of a malicious executable.", "correct": false },
        { "text": "A specific password for a compromised account", "correct": true }
      ],
      "explanation": "ANSWER: D \n An Indicator of Compromise (IOC) refers to specific artifacts or evidence that indicate a system has been compromised. IOCs include file hashes, malicious IP addresses, domain names, or other observable elements that can signal malicious activity. A specific password for a compromised account is not considered an IOC because it is a credential rather than an artifact of an attack. While compromised passwords are important for incident response, they are generally treated as part of account security and credentials management, not as IOCs."
    },
    {
      "question": "According to Splunk CIM documentation, which field in the Authentication Data Model represents the user who initiated a privilege escalation?",
      "answers": [
        { "text": "username", "correct": false },
        { "text": "src_user_id", "correct": false },
        { "text": "src_user", "correct": true },
        { "text": "dest_user", "correct": false }
      ],
      "explanation": "ANSWER: C \n According to Splunk's Common Information Model (CIM) documentation, the src_user field in the Authentication Data Model represents the user who initiated an action, such as a privilege escalation. This field captures the originating (source) user account performing the activity."
    },
    {
      "question": "The following list contains examples of Tactics, Techniques, and Procedures (TTPs): \n 1. Exploiting a remote service \n 2. Lateral movement \n 3. Use EternalBlue to exploit a remote SMB server \n In which order are they listed below?",
      "answers": [
        { "text": "Tactic, Technique, Procedure", "correct": true },
        { "text": "Procedure, Technique, Tactic", "correct": false },
        { "text": "Technique, Tactic, Procedure", "correct": false },
        { "text": "Tactic, Procedure, Technique", "correct": false }
      ],
      "explanation": "ANSWER: A \n 1.Exploiting a remote service → This is a Tactic, representing the broader goal or objective of the adversary. For example, under MITRE ATT&CK, 'Exploitation for Remote Services' falls under the Initial Access or Execution tactic. \n 2.Lateral movement → This is a Technique, as it describes a specific action taken by the adversary to move laterally through a network. It aligns with the Lateral Movement tactic in MITRE ATT&CK. \n 3. Use EternalBlue to exploit a remote SMB server** → This is a **Procedure**, representing the specific implementation of a technique. EternalBlue is a known exploit used to target SMB services to gain access"
    },
    {
      "question": "An analyst is attempting to investigate a Notable Event within Enterprise Security. Through the course of their investigation they determined that the logs and artifacts needed to investigate the alert are not available. What event disposition should the analyst assign to the Notable Event?",
      "answers": [
        { "text": "Benign Positive, since there was no evidence that the event actually occurred", "correct": false },
        { "text": "False Negative, since there are no logs to prove the activity actually occurred.", "correct": false },
        { "text": "True Positive, since there are no logs to prove that the event did not occur", "correct": false },
        { "text": "Other, since a security engineer needs to ingest the required logs", "correct": true }
      ],
      "explanation": "ANSWER: D \n When logs and artifacts necessary for investigating a Notable Event are missing, it is not possible to conclusively determine whether the event is a True Positive, False Positive, or any other disposition. In this case, the disposition 'Other' is appropriate because the root cause is an operational issue: the required data sources are not available. A follow-up action should be taken to ensure the missing logs are ingested, typically by involving a security engineer. \n ### Why the other options are incorrect: \n - A. Benign Positive:** A **Benign Positive** occurs when an alert is technically correct but does not represent malicious activity. This does not apply here because the logs are missing, and no conclusion can be drawn. \n - B. False Negative:** A **False Negative** occurs when a detection fails to identify malicious activity. This does not apply here, as the alert was generated. \n - C. True Positive:** A **True Positive** requires evidence to confirm the alert is valid. Since the logs are missing, there is no proof of malicious activity."
    },
    {
      "question": "An analyst is looking at Web Server logs, and sees the following entry as the last web request that a server processed before unexpectedly shutting down: 147.186.119.107 - - [28/Jul/2006:10:27:10 -0300] 'POST /cgi-bin/shutdown/ HTTP/1.0' 200 3333 What kind of attack is most likely occurring?",
      "answers": [
        { "text": "Distributed denial of service attack", "correct": false },
        { "text": "Denial of service attack.", "correct": true },
        { "text": "Database injection attack.", "correct": false },
        { "text": "Cross-Site scripting attack", "correct": false }
      ],
      "explanation": "ANSWER: B \n The log entry indicates a POST request to a suspicious path, /cgi-bin/shutdown/, which suggests that the attacker may have exploited a vulnerability or misconfiguration to send a command to shut down the web server. This kind of activity is characteristic of a Denial of Service (DoS) attack, where an attacker intentionally disrupts the availability of a service, in this case by forcing the server to shut down."
    },
    {
      "question": "Which of the Enterprise Security frameworks provides additional automatic context and correlation to fields that exist within raw data?",
      "answers": [
        { "text": "Asset and Identity", "correct": true },
        { "text": "Threat Intelligence", "correct": false },
        { "text": "Adaptive Response", "correct": false },
        { "text": "Risk", "correct": false }
      ],
      "explanation": "ANSWER: A \n The Asset and Identity framework in Splunk Enterprise Security enriches raw data by adding automatic context and correlation to fields like IP addresses, hostnames, and user accounts. This framework integrates asset (e.g., servers, endpoints) and identity (e.g., usernames, accounts) data, enabling analysts to better understand the entities involved in events and their relationships. It provides additional context such as asset category, priority, and user roles, which improves investigation and prioritization."
    }
  ]
  